import streamlit as st
import pandas as pd
import random
from utils import save_user_data

st.set_page_config(page_title="×¡×™× ×•×Ÿ ××™×œ×™×", page_icon="ğŸ”")

# ×”×’× ×” ×¢×œ ×”×¢××•×“
if not st.session_state.get('logged_in'):
    st.warning("×× × ×”×ª×—×‘×¨ ×“×¨×š ×¢××•×“ ×”×‘×™×ª.")
    st.stop()

user_data = st.session_state.user_data


@st.cache_data
def load_lexicon():
    # ×˜×¢×™× ×ª ×§×•×‘×¥ ×”××™×œ×™× ××”×ª×™×§×™×™×” ×”××§×•××™×ª
    df = pd.read_csv("data/psychometry_words.csv")
    return df


df_full = load_lexicon()

st.title("×¡×™× ×•×Ÿ ××™×œ×™× ×—×“×©×•×ª ğŸ”")

# --- 1. ×‘×—×™×¨×ª ×¨××” (Level) ---
available_levels = sorted(df_full['Level'].unique().tolist())
selected_level = st.selectbox("×‘×—×¨ ×¨××ª ×§×•×©×™ ×œ×ª×¨×’×•×œ:", available_levels)

# ×”×’×“×¨×ª ×”××™×œ×™× ×©×›×‘×¨ ×¨××™× ×• (×›×“×™ ×œ×¡× ×Ÿ ××•×ª×Ÿ ××”×ª×•×¨ ×”×—×“×©)
seen_words = set(user_data.get("learned", [])) | set(user_data.get("learning", {}).keys())

# --- 2. ×œ×•×’×™×§×ª × ×™×”×•×œ ×ª×•×¨ ×”××™×œ×™× (×ª×™×§×•×Ÿ ×”-IndexError) ---
# ×× ×—× ×• ×™×•×¦×¨×™× ×ª×•×¨ ×©×œ ××™×œ×™× (Strings) ×•×œ× ××™× ×“×§×¡×™× ××¡×¤×¨×™×™×
if 'filter_queue' not in st.session_state or st.session_state.get('last_level') != selected_level:
    # ×¡×™× ×•×Ÿ ×¨××©×•× ×™ ×©×œ ××™×œ×™× ×œ×¨××” ×©× ×‘×—×¨×” ×©×˜×¨× × ×¨××•
    level_df = df_full[df_full['Level'] == selected_level]
    remaining_words_df = level_df[~level_df['Word'].astype(str).str.lower().isin(seen_words)]

    # ×™×¦×™×¨×ª ×¨×©×™××ª ×”××™×œ×™× ×•×¢×¨×‘×•×‘×”
    queue = remaining_words_df['Word'].tolist()
    random.shuffle(queue)

    st.session_state.filter_queue = queue
    st.session_state.current_filter_index = 0
    st.session_state.last_level = selected_level

# ×‘×“×™×§×” ×× ×”×ª×•×¨ ×¨×™×§ ××• ×©×¡×™×™×× ×• ××•×ª×•
if not st.session_state.filter_queue or st.session_state.current_filter_index >= len(st.session_state.filter_queue):
    st.balloons()
    st.success(f"×›×œ ×”×›×‘×•×“! ×¡×™×™××ª ××ª ×›×œ ×”××™×œ×™× ×‘×¨××” {selected_level}! ğŸ‰")
    if st.button("×—×–×•×¨ ×œ×“×©×‘×•×¨×“ ğŸ ", use_container_width=True):
        st.switch_page("pages/1_dashboard.py")
    st.stop()

# ×©×œ×™×¤×ª ×”××™×œ×” ×”× ×•×›×—×™×ª ××ª×•×š ×”×ª×•×¨ ×”××¢×•×¨×‘×‘
current_word = st.session_state.filter_queue[st.session_state.current_filter_index]

# ×©×œ×™×¤×ª × ×ª×•× ×™ ×”××™×œ×” (×ª×¨×’×•×) ××ª×•×š ×”-DF ×”××œ× ×œ×¤×™ ×”××™×œ×” ×¢×¦××” (×‘×˜×•×— ×œ×’××¨×™)
word_row = df_full[df_full['Word'] == current_word].iloc[0]
word = str(word_row['Word']).strip()
translation = str(word_row['Translation']).strip()

st.markdown(f"### ×”××™×œ×”:")
st.info(f"## {word}")

with st.expander("×œ×—×¥ ×›××Ÿ ×œ×¦×¤×™×™×” ×‘×ª×¨×’×•×"):
    st.write(f"**×ª×¨×’×•×:** {translation}")

# --- 3. ××œ×œ ×¨××” ×•×¡×¤×™×¨×” ××ª×—×ª ×œ×ª×¨×’×•× ---
remaining_count = len(st.session_state.filter_queue) - st.session_state.current_filter_index
st.write(f"×¨××”: {selected_level} | ××™×œ×™× ×©× ×•×ª×¨×• ×‘×ª×•×¨ ×”× ×•×›×—×™: {remaining_count}")

st.write("---")
col1, col2, col3 = st.columns(3)


def next_word():
    """×§×™×“×•× ×”××™× ×“×§×¡ ×‘×ª×•×¨ ×•××¢×‘×¨ ×œ××™×œ×” ×”×‘××”"""
    st.session_state.current_filter_index += 1
    st.rerun()


with col1:
    if st.button("âœ… ×™×•×“×¢", use_container_width=True):
        if word.lower() not in user_data["learned"]:
            user_data["learned"].append(word.lower())
            save_user_data(user_data)  # ×©××™×¨×” ×œ×¢× ×Ÿ Supabase
        next_word()

with col2:
    if st.button("ğŸ“– ×¨×•×¦×” ×œ×œ××•×“", use_container_width=True):
        user_data["learning"][word.lower()] = {"translation": translation, "score": 0}
        save_user_data(user_data)  # ×©××™×¨×” ×œ×¢× ×Ÿ Supabase
        next_word()

with col3:
    if st.button("â­ï¸ ×“×œ×’", use_container_width=True):
        next_word()

if st.button("×—×–×•×¨ ×œ×“×©×‘×•×¨×“ ğŸ ", use_container_width=True):
    st.switch_page("pages/1_dashboard.py")